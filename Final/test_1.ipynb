{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.634705531722\n",
      "Time of work =  0:01:01.758262\n",
      "10 0.664587137728\n",
      "Time of work =  0:01:57.444897\n",
      "20 0.682015122953\n",
      "Time of work =  0:03:52.778148\n",
      "30 0.689156519957\n",
      "Time of work =  0:05:45.002559\n",
      "40 0.694262120354\n",
      "Time of work =  0:07:38.051232\n",
      "45 0.696057085524\n",
      "Time of work =  0:08:39.966769\n",
      "50 0.697546279241\n",
      "Time of work =  0:09:37.326525\n",
      "55 0.69880283734\n",
      "Time of work =  0:10:36.979186\n",
      "60 0.699974098913\n",
      "Time of work =  0:11:44.643634\n",
      "65 0.701096062688\n",
      "Time of work =  0:12:37.893317\n",
      "70 0.702029755609\n",
      "Time of work =  0:13:38.010306\n",
      "[0.63470553172218414, 0.66458713772835831, 0.6820151229527236, 0.68915651995687222, 0.69426212035371271, 0.69605708552422896, 0.69754627924141155, 0.69880283734005899, 0.69997409891289608, 0.70109606268792712, 0.70202975560910919]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import datetime\n",
    "\n",
    "features = pd.read_csv('features.csv', index_col='match_id')\n",
    "\n",
    "############################### Градиентный бустинг ##############################\n",
    "#данные, которые известны по первым пяти минутам\n",
    "features_X = features.ix[:,0:102]\n",
    "features_X = features_X.fillna(0)\n",
    "\n",
    "# Поскольку мы пытаемся определить, кто выиграл матч, то столбец, который содержит целевую переменную - radiant_win.\n",
    "features_y = np.ravel(features.ix[:,'radiant_win':'radiant_win'])\n",
    "\n",
    "# выведу на печать названия столбцов с пропусками\n",
    "for i in range(102):\n",
    "    if features_X.ix[:,i:i+1].count()[0] < len(features_X.ix[:,0:1]):\n",
    "        print(features_X.ix[:,i:i+1].columns.values[0])\n",
    "\n",
    "# аналогично, но в одну строку\n",
    "#features_with_pass = [features_clean.ix[:,i:i+1].columns.values[0] for i in range(102) if features_clean.ix[:,i:i+1].count()[0] < len(features_clean.ix[:,i:i+1])]\n",
    "#print(features_with_pass)\n",
    "\n",
    "\n",
    "# cross-validation\n",
    "# проводим по пяти блокам\n",
    "kf = KFold(len(features_X.ix[:,0:1]), n_folds=5,random_state=13, shuffle=True)\n",
    "\n",
    "est = [] #estimations\n",
    "start_time = datetime.datetime.now()\n",
    "for num_tree in [5,10,20,30,40,45,50,55,60,65,70]:\n",
    "    clf = GBC(n_estimators=num_tree,random_state=13)\n",
    "    Pred = clf.fit(features_X, features_y)\n",
    "    Estimation = cross_val_score(Pred, features_X, y=features_y, scoring='roc_auc', cv=kf).mean()\n",
    "    est.append(Estimation)\n",
    "    print(num_tree, Estimation)\n",
    "    print(\"Time of work = \", datetime.datetime.now() - start_time)\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "# Выведу список оценок \n",
    "print(est)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### График изменения качества  от числа деревье"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff0c1d32ba8>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XuUVfV99/H3h4sXUBFEUSEQLwGJl3iJYKOpJ2BwJEZ9\nspIIpKZNm5QnkZXk6ZMW267WsavJql3W5mbySLXWpkbTShMwAblETqoNxrGCaGAE4w0GQTHeLwjD\n9/njd8Y5jDPMOcyZ2efyea111jn7cvb5ngE+s/nu395bEYGZmTWGQVkXYGZmA8ehb2bWQBz6ZmYN\nxKFvZtZAHPpmZg3EoW9m1kBKCn1JTZJaJW2UNL+b5V+TtEbSQ5IekbRb0uGFZTdL2i5pXaWLNzOz\n8qi3cfqSBgEbgenAVqAFmBURrT2sfzHw1Yi4oDB9HvAa8K8RcVoFazczszKVsqc/BdgUEU9HxC7g\nDuDSfaw/G7i9YyIi7gNe7FOVZmZWEaWE/lhgc9H0lsK8d5F0MNAELOx7aWZmVmmVPpD7ceC+iHip\nwts1M7MKGFLCOm3A+KLpcYV53ZlFUWunHJJ8ESAzszJFhMpZv5Q9/RbgREkTJB1ACvbFXVeSNAI4\nH1jUzTZUeOxTRNTk4+qrr868BteffR2uvzYftVz//ug19COiHZgHLAd+DdwRERskzZX0x0WrXgYs\ni4g3i98v6YfAL4GJkp6R9Ln9qtTMzPqslPYOEXE3MKnLvBu7TN8K3NrNe+f0pUAzM6scn5FbAblc\nLusS+sT1Z8v1Z6vW6y9XrydnDRRJUS21mJnVAklEPxzINTOzOuHQNzNrIA59M7MG4tA3M2sgDn0z\nswbi0DczayAOfTOzBuLQNzNrIA59M7MG4tA3M2sgDn0zswbi0DczayAOfTOzBuLQNzNrICXdRMXM\nzKpHBLzwwv6916FvZlZF9uyB7dthyxZoa0vP3T127ty/7Tv0zcwGyK5d8Oyz+w7zrVth9+7etzVi\nBLz8cvk1lBT6kpqAb5KOAdwcEdd2Wf414DNAAEOBycDoiHipt/eamdWLV16BJ59MjyeegKee2jvQ\nt21LrZneHHkkjBsHY8em566PsWPhkENAZd0zK+n1domSBgEbgenAVqAFmBURrT2sfzHw1Yi4oJz3\n+naJZlbtdu2CzZtToHcEe8fzE0/03meX4Jhj9h3oxx4LBx1UWj37c7vEUvb0pwCbIuLpwofcAVwK\ndBv6wGzg9v18r5lZZiLg+ee7D/Unn4Rnnkk9954cdBAcdxwcf3x6Pu44eM97OgP96KNh6NCB+z7d\nKSX0xwKbi6a3kML8XSQdDDQBV5b7XjOzgfDWWynAf/Obzj304nB/442e3yulEO8I9a7PRx+9fy2X\ngVTpA7kfB+6LiJcqvF0zs5K9+GIK9e4ebW377quPHNl9oB9/PIwfDwceOHDfoz+UEvptwPii6XGF\ned2ZRWdrp9z30tzc/M7rXC5HLpcroTwzazR79qRRLj0F+4sv9vzewYPhve+FE05IQX7CCXuH++GH\nD9jXKFs+nyefz/dpG6UcyB0MPEY6GPss8AAwOyI2dFlvBPAEMC4i3iznvYV1fSDXzN7x9tudbZiu\njyefTG2angwfnsK8u8f48TCkTgar98uB3IholzQPWE7nsMsNkuamxbGgsOplwLKOwN/Xe8sp0Mzq\nV3t7Gg2zcSNs2pSeO14/9VRa3pOjjuo52I86qvp761npdU9/oHhP36w+RaQTkjpCvfj58cfTHn13\nJJgwYe8wP/HEzrbMoYcO7PeoRv01ZNPMrFcvvPDuUO94fv31nt937LHwvvfBxIl7Px9/fOnj1a10\nDn0zK1lEOrP00UfhkUfSc0dLZl8HT4844t2hPnFi2nM/5JCBq98c+mbWg9/+du9w73ju6Xovhx7a\n/R77+94Ho0YNbO3WM4e+WYN74w3YsOHd4b51a/frjx4Np54Kp5ySHpMnp2AfM8YHT2uBQ9+sQeze\nnfrrXffef/Ob7k9WGjYMTj45BXxHyJ96qkfG1DqHvlkdevVV+J//gZYWWLcuhfuGDd2PlBkyBCZN\n6gz1jj34446DQb63Xt1x6JvVuLffTsH+wAMp5B94IAV8d3vvEybsvdd+yikp8Gv90gJWOoe+WQ3Z\nsyeNlOkI9wcegLVr370HP3QonHYanH02nHlmCveTT4bDDsumbqseDn2zKhWRLg5WvAf/4IPpRh1d\nTZoEU6akx9lnwwc+4DHu1j2HvlmVePHFFOode/AtLelM1q7Gju0M9ylT4KyzqvsiYVZdHPpmGXnq\nKViyBP77v1PAb9r07nUOPzyFe0fAn312OoPVbH859M0GSHs73H8//PSn6fHoo3svP/DA1H/vCPgp\nU9J1ZjyCxirJoW/Wj15+GZYtSyG/ZMne91A99FC48EKYPj0F/KmnZn8rPat/Dn2zCtu0KYX8XXfB\nvfemk6I6HH88fPzj6fHhD8MBB2RXpzUmh75ZH+3aBffd19m22bixc9ngwXD++XDxxekxaZLPZrVs\nOfTN9sMLL8DSpSnk775774uQjRwJF12UQv7CC32xMasuDn2zEkTA+vWdbZvVq9OJUh0mT+7cm//Q\nh+rndnxWf/xX06wHO3fCL37R2bZ58snOZUOHwrRpnUF/wgnZ1WlWDoe+WZHt2+FnP0shv3z53nd8\nOvJI+NjHUsh/9KO+pIHVppJCX1IT8E06b25+bTfr5IB/BIYCz0fERwrzvwJ8vrDaP0XEtytQt1lF\nRKRr13TszT/wwN7LTzstjbS5+OI0fn7w4GzqNKuUXm+MLmkQsBGYDmwFWoBZEdFatM4I4JfAjIho\nkzQ6InZIOhm4HTgb2A0sBf53RDzRzef4xug2IN54A+65pzPo29o6lx14YBo3f/HFaa9+/Pjs6jTr\nTX/dGH0KsCkini58yB3ApUBr0TpzgIUR0QYQETsK8ycDv4qInYX3/hfwCeC6coo066stW1Lb5q67\n4Oc/h7fe6lx2zDGdvfnp02H48OzqNOtvpYT+WGBz0fQW0i+CYhOBoZJWAYcA346IHwCPAn8raSSw\nE5hJ+p+CWb/asyddvOyuu9Le/Nq1ey//4Ac72zZnnOGx89Y4KnUgdwhwJjANGA6slrQ6IlolXQus\nAF4D1gDtPW2kubn5nde5XI5cLleh8qwRvPoqrFiRQv5nP4PnnutcNmwYzJiRQn7mzLR3b1Zr8vk8\n+Xy+T9sopad/DtAcEU2F6auAKD6YK2k+cFBEXFOYvglYGhELu2zr68DmiPh/3XyOe/pWti1b4Mc/\nTkGfz+99M5Hx4zv35nM5X1/e6k9/9fRbgBMlTQCeBWYBs7usswj4jqTBwIHAVOD6QlFHRsTzksYD\n/ws4p5wCzbqKSH35G26AxYs7T5KS0olRHf35U05x28asq15DPyLaJc0DltM5ZHODpLlpcSwotHGW\nAetI7ZsFEbG+sImFkkYBu4AvRUQ39/0x691LL8Gtt8L3vw+PPZbmDR0Kl10Gl16aLn1w5JHZ1mhW\n7Xpt7wwUt3esJw8/nPbqb7stDbcEGDcO5s6Fz38ejj462/rMstJf7R2zAff223DnnfC976U7S3WY\nPh2uvDL16n19G7Py+Z+NVZVnnoEFC+Cf/qlz9M1hh8Ef/AF88Ytw0kmZlmdW8xz6lrmeDsyeemra\nq//MZ+CQQ7Kt0axeOPQtMx0HZr/3vc4bjwwdCp/+dAr7c8/16BuzSnPo24DzgVmz7Dj0bUDs3AkL\nF6aw/+UvO+f7wKzZwPI/M+tXzzwDN94IN93kA7Nm1cChbxW3Z0/ngdm77uo8MHvaaWmvfs4cH5g1\ny4pD3yrmpZfgX/4lnTFbfGD28svhS1/ygVmzauDQtz5buzaNwPGBWbPq59C3/bJzZ+cZsz4wa1Y7\n/M/SyuIDs2a1zaFvvfKBWbP64dC3HvnArFn9cejbu6xd23nG7Jtvpnk+MGtWHxz6BnQemL3hBli9\nunO+D8ya1Rf/M25w27fDt7+dLmX8/PNpng/MmtUvh34De+opOP/8NCIHfGDWrBE49BvUM8/AtGnp\n+eyz4frrfWDWrBEMKmUlSU2SWiVtlDS/h3VyktZIelTSqqL5/6cwb52k2yQdUKnibf9s2ZIC/8kn\nYcoUWLECzjvPgW/WCHq9MbqkQcBGYDqwFWgBZkVEa9E6I4BfAjMiok3S6IjYIelY4D7gpIh4W9KP\ngJ9FxL928zm+MfoA2LoVcjnYtAnOOgtWroTDD8+6KjPbH/tzY/RS9vSnAJsi4umI2AXcAVzaZZ05\nwMKIaAOIiB1FywYDwyUNAYaRfnFYBrZtS3v4mzbB6afD8uUOfLNGU0rojwU2F01vKcwrNhEYJWmV\npBZJVwBExFbgH4BngDbgpYhY2feyrVzPPZeGXz72WDpgu3IljBqVdVVmNtAqdSB3CHAmMA0YDqyW\ntBrYQfpfwQTgZeBOSXMi4ofdbaS5ufmd17lcjlwuV6HyGtuOHSnw16+Hk09OgX/EEVlXZWblyufz\n5PP5Pm2jlJ7+OUBzRDQVpq8CIiKuLVpnPnBQRFxTmL4JWAoIuDAivlCYfwUwNSLmdfM57un3gxde\nSIH/8MMweTKsWgVjxmRdlZlVQn/19FuAEyVNKIy8mQUs7rLOIuA8SYMlDQOmAhtIbZ1zJB0kSaSD\nwRvKKdD234svwkc/mgJ/4sR00TQHvllj67W9ExHtkuYBy0m/JG6OiA2S5qbFsSAiWiUtA9YB7cCC\niFgPIOlOYA2wq/C8oJ++ixV56SWYMQPWrIETT4R77oFjjsm6KjPLWq/tnYHi9k7lvPJKCvxf/QqO\nPx5+8Yt0wTQzqy/91d6xGvLqq3DRRSnw3/ve1MN34JtZB4d+HXntNZg5M92+cPz4FPjjx2ddlZlV\nE4d+nXj9dbj4YrjvvrRnf889aU/fzKyYQ78OvPkmXHJJ6t0fc0wK/BNOyLoqM6tGDv0a99ZbcNll\nKejHjEktnfe9L+uqzKxaOfRr2M6d8IlPpGvoHHVUCv5Jk7KuysyqmUO/Rr39Nnzyk7B0KYwenU68\nev/7s67KzKqdQ78G7doFn/40/PSn6aJpP/85nHJK1lWZWS1w6NeYXbtg9mxYtAhGjkwXTzvttKyr\nMrNa4dCvIbt3wxVXwMKFMGJEuuPVGWdkXZWZ1RKHfo1ob4ff/3340Y/gsMPSwduzzsq6KjOrNQ79\nGtDeDp/7HPzwh3DIIXD33enetmZm5XLoV7k9e+ALX4Af/ACGD0+jdX7nd7KuysxqlUO/iu3ZA3Pn\nwi23wLBhsGQJnHde1lWZWS1z6FepCJg3D266CQ4+OA3P/N3fzboqM6t1Dv0qFAFf+Qp8//tw4IGw\neDF85CNZV2Vm9cChX2Ui4E/+BL7zHTjgAPjJT+CCC7KuyszqhUO/ikTAn/0ZfPObMHQo/Od/QlNT\n1lWZWT1x6FeJCPiLv4DrroMhQ+DOO+FjH8u6KjOrNyWFvqQmSa2SNkqa38M6OUlrJD0qaVVh3sTC\nvIcKzy9L+nIlv0C9uPpq+Lu/g8GD4d//PV0f38ys0nq9MbqkQcBGYDqwFWgBZkVEa9E6I4BfAjMi\nok3S6IjY0c12tgBTI2JzN5/TsDdG/5u/SaE/eDDcfjt86lNZV2RmtaC/bow+BdgUEU9HxC7gDuDS\nLuvMARZGRBtA18AvuAD4TXeB38i+8Y0U+IMGwb/9mwPfzPpXKaE/FigO6i2FecUmAqMkrZLUIumK\nbrZzOXD7/pVZn/7+7+Ev/xIkuPVWmDUr64rMrN4NqeB2zgSmAcOB1ZJWR8TjAJKGApcAV+1rI83N\nze+8zuVy5HK5CpVXfa6/HubPT4F/yy3we7+XdUVmVu3y+Tz5fL5P2yilp38O0BwRTYXpq4CIiGuL\n1pkPHBQR1xSmbwKWRsTCwvQlwJc6ttHD5zRMT//b304nX0E64/aP/ijbesysNvVXT78FOFHSBEkH\nALOAxV3WWQScJ2mwpGHAVGBD0fLZuLUDwPe+1xn4N97owDezgdVreyci2iXNA5aTfkncHBEbJM1N\ni2NBRLRKWgasA9qBBRGxHqDwS+AC4I/77VvUiAUL4Mor0+sbboA/bvifiJkNtF7bOwOl3ts7//zP\nnXv13/oWfNlnK5hZH/VXe8f66NZb4fOfT6//4R8c+GaWHYd+P7vttnTXqwi49tp0MTUzs6w49PvR\nj34En/1sCvyvfz1dTM3MLEsO/X5y553wmc+ku19dc026mJqZWdYc+v3gxz+G2bPTDc3/6q/gr/86\n64rMzBKHfoUtXgyf/jTs3g1//udpL9/MrFo49CtoyRL45CdT4H/ta6mPr7IGU5mZ9S+HfoUsWwaf\n+ATs2gVf/Wq6mJoD38yqjUO/AlauhMsug507Yd68dDE1B76ZVSOfkdtH998P06bBm2/CF7+YLq/g\nwDezgeAzcjPwjW+kwP/DP4TvfteBb2bVzXv6ffDWW3DEEfDGG9DWBscem3VFZtZIvKc/wO69NwX+\n6ac78M2sNjj0+2DJkvR80UXZ1mFmViqHfh8sXZqeHfpmVivc099PTzwBJ5wAI0bAjh0wpFJ3GzYz\nK5F7+gOoYy9/xgwHvpnVDof+fuoI/Zkzs63DzKwcbu/sh7feglGj0vj8Z5+Fo4/OuiIza0T91t6R\n1CSpVdJGSfN7WCcnaY2kRyWtKpo/QtJ/SNog6deSppZTYDX6xS9S4J9xhgPfzGpLr91oSYOA7wLT\nga1Ai6RFEdFatM4I4AZgRkS0SRpdtIlvAUsi4lOShgDDKvoNMtAxVNOtHTOrNaXs6U8BNkXE0xGx\nC7gDuLTLOnOAhRHRBhAROwAkHQZ8OCJuKczfHRGvVKz6jHioppnVqlJCfyywuWh6S2FesYnAKEmr\nJLVIuqIw/zhgh6RbJD0kaYGkg/tednYefxw2bYKRI2FqzTeqzKzRVGqw4RDgTGAaMBxYLWl10fwr\nI+JBSd8ErgKu7m4jzc3N77zO5XLkcrkKlVc5HqppZlnJ5/Pk8/k+baPX0TuSzgGaI6KpMH0VEBFx\nbdE684GDIuKawvRNwFLgPmB1RBxfmH8eMD8iPt7N59TE6J2ZM1Pw33orfPazWVdjZo2sv0bvtAAn\nSpog6QBgFrC4yzqLgPMkDZY0DJgKbIiI7cBmSRML600H1pdTYDV5801YVRiXdOGF2dZiZrY/em1Q\nRES7pHnActIviZsjYoOkuWlxLIiIVknLgHVAO7AgIjrC/cvAbZKGAk8An+uXbzIA8vk0Rv+ss2DM\nmKyrMTMrX0ld6Yi4G5jUZd6NXaavA67r5r0PA2f3ocaq4aGaZlbrfBmGEkX4UspmVvt8GYYSbdwI\nkyalyy889xwMHpx1RWbW6HyVzX7UMVTzwgsd+GZWuxz6JfJVNc2sHri9U4I33khtnbffhu3b4cgj\ns67IzMztnX6zahXs3Akf/KAD38xqm0O/BB6qaWb1wqHfCw/VNLN64p5+L1pbYfJkGD0atm3zyB0z\nqx7u6fcDD9U0s3ri0O+Fb5hiZvXE7Z19eO01OOII2LUrnYU7enTv7zEzGyhu71TYqlVpbP6UKQ58\nM6sPDv198FBNM6s3Dv0eRLifb2b1xz39HqxfDyefnM7A3bYNBvnXo5lVGff0K6hjL7+pyYFvZvXD\ncdYDt3bMrB65vdONV19NQzXb29NQzSOOyLoiM7N367f2jqQmSa2SNkqa38M6OUlrJD0qaVXR/Kck\nPVxY9kA5xWXlnnvS2PypUx34ZlZfer0xuqRBwHeB6cBWoEXSoohoLVpnBHADMCMi2iQVj2rfA+Qi\n4sXKlt5/PFTTzOpVKXv6U4BNEfF0ROwC7gAu7bLOHGBhRLQBRMSOomUq8XOqgodqmlk9KyWMxwKb\ni6a3FOYVmwiMkrRKUoukK4qWBbCiMP8LfSu3//3617B5M4wZA2eckXU1ZmaV1Wt7p4ztnAlMA4YD\nqyWtjojHgXMj4llJR5LCf0NE3NfdRpqbm995ncvlyOVyFSqvdB6qaWbVKp/Pk8/n+7SNXkfvSDoH\naI6IpsL0VUBExLVF68wHDoqIawrTNwFLI2Jhl21dDbwaEdd38zlVMXpn2rR0zZ077oDLL8+6GjOz\nnvXX6J0W4ERJEyQdAMwCFndZZxFwnqTBkoYBU4ENkoZJOqRQ3HBgBvBoOQUOpFdegXvvTXv4M2Zk\nXY2ZWeX12t6JiHZJ84DlpF8SN0fEBklz0+JYEBGtkpYB64B2YEFErJd0HPBjSVH4rNsiYnn/fZ2+\n+fnPYfduOPdcGDky62rMzCqvpJ5+RNwNTOoy78Yu09cB13WZ9yRweh9rHDAeqmlm9c6HKgs8VNPM\nGoFDv+CRR6CtDY45Bk6vmf+bmJmVx6FfUDxUU2UdCzczqx0O/QK3dsysEfgqm8DLL3deWG3HDjj8\n8EzKMDMri2+isp9WrkyXUf7Qhxz4ZlbfHPp4qKaZNY6GD30P1TSzRtLwof/ww/Dss3DssXDaaVlX\nY2bWvxo+9Iv38j1U08zqnUPfrR0zayANPWTzpZdg9Oi0h79jB4wYMaAfb2bWJx6yWaYVK9JQzXPP\ndeCbWWNo6ND3UE0zazQNG/p79sDdd6fX7uebWaNo2NBfuxa2bYOxY+GUU7KuxsxsYDRs6HeM2pk5\n00M1zaxxNHzou7VjZo2kpNCX1CSpVdJGSfN7WCcnaY2kRyWt6rJskKSHJHW9oXomfvtbWL0ahg6F\n6dOzrsbMbOD0eo9cSYOA7wLTga1Ai6RFEdFatM4I4AZgRkS0SRrdZTNfAdYDh1Ws8j5YsSIdyD3/\nfDisKioyMxsYpezpTwE2RcTTEbELuAO4tMs6c4CFEdEGEBE7OhZIGgfMBG6qTMl956GaZtaoSgn9\nscDmoukthXnFJgKjJK2S1CLpiqJl/wj8KVAVp/56qKaZNbJe2ztlbOdMYBowHFgtaTUwCdgeEWsl\n5YDMx8k89BA89xy85z3w/vdnXY2Z2cAqJfTbgPFF0+MK84ptAXZExFvAW5L+C/gAcBZwiaSZwMHA\noZL+NSI+290HNTc3v/M6l8uRy+VK/Bql81BNM6tV+XyefD7fp230esE1SYOBx0gHcp8FHgBmR8SG\nonVOAr4DNAEHAr8CLo+I9UXrnA/834i4pIfPGZALrn3oQ2nkzk9+Apd2PTJhZlZD9ueCa73u6UdE\nu6R5wHLSMYCbI2KDpLlpcSyIiFZJy4B1QDuwoDjwq8ULL8D993uoppk1roa6tPLtt8OcOSnwV67s\n148yM+t3vrRyLzqGanrUjpk1qobZ09+zB8aMSTdLWb8eJk/ut48yMxsQ3tPfhwcfTIE/YQKcdFLW\n1ZiZZaNhQt9DNc3MGjD03c83s0bWED39559P/fyhQ9MVNocP75ePMTMbUO7p92D5cohIV9V04JtZ\nI2uI0PdQTTOzpO7bO+3tqbXzwgvQ2gqTJlX8I8zMMuH2TjdaWlLgH3ccTJyYdTVmZtmq+9D3UE0z\ns051H/qnngpNTXBJt9f2NDNrLHXf0zczq1fu6ZuZ2T459M3MGohD38ysgTj0zcwaiEPfzKyBOPTN\nzBpISaEvqUlSq6SNkub3sE5O0hpJj0paVZh3oKRfFeY/IunqShZvZmbl6TX0JQ0CvgtcCJwMzJZ0\nUpd1RgA3ABdHxCnApwAiYifwkYg4AzgduEjSlMp+hezl8/msS+gT158t15+tWq+/XKXs6U8BNkXE\n0xGxC7gDuLTLOnOAhRHRBhAROzoWRMQbhZcHAkOAujsDq9b/0rj+bLn+bNV6/eUqJfTHApuLprcU\n5hWbCIyStEpSi6QrOhZIGiRpDbANWBERLX0t2szM9s+QCm7nTGAaMBxYLWl1RDweEXuAMyQdBvxE\n0vsjYn2FPtfMzMrQ67V3JJ0DNEdEU2H6KiAi4tqideYDB0XENYXpm4ClEbGwy7b+Cng9Iq7v5nPq\nru1jZtbfyr32Til7+i3AiZImAM8Cs4DZXdZZBHxH0mBS734qcL2k0cCuiHhZ0sHAR4G/q0ThZmZW\nvl5DPyLaJc0DlpOOAdwcERskzU2LY0FEtEpaBqwD2oEFEbFe0qnArYURQIOAH0XEkv77OmZmti9V\nc2llMzPrf5mfkVvKiV/VRNLNkrZLWlc0b6Sk5ZIek7SscN5CVZI0TtI9kn5dOGHuy4X5Vf8dejrZ\nrxZqL1YY0faQpMWF6ZqpX9JTkh4u/Bk8UJhXS/WPkPQfkjYU/g1MrZX6JU0s/NwfKjy/LOnL5daf\naeiXcuJXFbqFVG+xq4CVETEJuAf48wGvqnS7gT+JiJOB3wGuLPzMq/477ONkv6qvvYuvAMUj2Gqp\n/j1ALiLOiIiOEy1rqf5vAUsiYjLwAaCVGqk/IjYWfu5nAmcBrwM/ptz6IyKzB3AOaZRPx/RVwPws\nayqx7gnAuqLpVmBM4fXRQGvWNZbxXX4CXFBr3wEYBjwInF1LtQPjgBVADlhca39/gCeBI7rMq4n6\ngcOA33Qzvybq71LzDODe/ak/6/ZOKSd+1YKjImI7QERsA47KuJ6SSHovaY/5ftJfmqr/Dj2c7FcT\ntRf8I/Cn7H1mei3VH8CKwkmYny/Mq5X6jwN2SLql0CJZIGkYtVN/scuBHxZel1V/1qFfr6r+6Lik\nQ4A7ga9ExGu8u+aq/A4RsSdSe2ccMEXSydRI7ZI+BmyPiLXAvoYoV2X9BedGai/MJLUGP0yN/Pzp\nPIn0hsJ3eJ3UXaiV+gGQNBS4BPiPwqyy6s869NuA8UXT4wrzas12SWMAJB0NPJdxPfskaQgp8H8Q\nEYsKs2vqO0TEK0AeaKJ2aj8XuETSE8DtwDRJPwC21Uj9RMSzhefnSa3BKdTOz38LsDkiHixMLyT9\nEqiV+jtcBPxPdF7jrKz6sw79d078knQA6cSvxRnXVAqx957aYuAPCq9/n3SyWjX7Z2B9RHyraF7V\nfwdJoztGJhSd7LeBGqgdICL+IiLGR8TxpL/r90TEFcBd1ED9koYV/oeIpOGkvvIj1M7PfzuwWdLE\nwqzpwK+pkfqLzCbtNHQor/4qOCDRBDwGbAKuyrqeEur9IbAV2Ak8A3wOGAmsLHyP5cDhWde5j/rP\nJZ1AtxaG0uC1AAAAg0lEQVRYAzxU+DMYVe3fATi1UO9a0omAf1mYX/W1d/NdzqfzQG5N1E/qiXf8\nvXmk499rrdRfqPUDpJ3NtcB/AiNqrP5hwPPAoUXzyqrfJ2eZmTWQrNs7ZmY2gBz6ZmYNxKFvZtZA\nHPpmZg3EoW9m1kAc+mZmDcShb2bWQBz6ZmYN5P8DAIzfqcDwYQkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff0c2447630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "num_tree = [5,10,20,30,40,45,50,55,60,65,70]\n",
    "Estimation = [0.63470553172218414, 0.66458713772835831, 0.6820151229527236, 0.68915651995687222, 0.69426212035371271, 0.69605708552422896, 0.69754627924141155, 0.69880283734005899, 0.69997409891289608, 0.70109606268792712, 0.70202975560910919]\n",
    "\n",
    "plt.plot(num_tree, Estimation, linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Целевая переменная\n",
    "Поскольку мы пытаемся определить, кто выиграл матч, то столбец, который содержит целевую переменную - __radiant_win__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Признаки, пропущенные для 12 столбцов:\n",
    "first_blood_time,\n",
    "first_blood_team,\n",
    "first_blood_player1,\n",
    "first_blood_player2,\n",
    "radiant_bottle_time,\n",
    "radiant_courier_time,\n",
    "radiant_flying_courier_time,\n",
    "radiant_first_ward_time,\n",
    "dire_bottle_time,\n",
    "dire_courier_time,\n",
    "dire_flying_courier_time,\n",
    "dire_first_ward_time.\n",
    "\n",
    "Первым 4-м событиям соотвествует момент первого убийства героя в игре. Раз есть пропуски, значит к 6-й минуте ни одного убийства совершено не было. Это может говорить о том, что уровень игроков в командах примерый равный, игроки, скорее, всего осторожничают:)\n",
    "Далее 8 признаков, по четыре для каждой команды. Есть пропуск, значит никто не преобретал предметы bootle, courier, flying_courier, наблюдатель также не был установлен."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Время выполнения кросс-валидации. Качество.\n",
    "Для градиентного бустинга с 30 деревьями 5 минут 45 секунд (железо Core i3 2.24GHz, 3MB L2 cash).\n",
    "Качество примерно 0,689 в этом случае.\n",
    "\n",
    "Изменял количество деревьев с 5 до 70. Мне кажется, что есть смысл использовать 40 деревьев, а вот больше - уже вопрос. При росте числа деревьев с 30 до 40 качество классификации растёт на 0,005, то есть на 0,5%, а вот при росте с 40 до 70 - 0,8%. При этом время обучения увеличивавется с 7 минут 38 сек до 13 минут 38 секунд.\n",
    "\n",
    "### Уменьшения временным затрат\n",
    "Для этого, как предлагается разработчиками, можно сделать подвыборку и уменьшить число деревьев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Уменьшение глубины дерева\n",
    "Попробую уменьшить глубину дерева с 3 до 2 и оценить влияение этого фактора на время выполнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество =  0.682005440034\n",
      "Time of work =  0:03:56.700292\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import datetime\n",
    "\n",
    "features = pd.read_csv('features.csv', index_col='match_id')\n",
    "\n",
    "############################### Градиентный бустинг ##############################\n",
    "#данные, которые известны по первым пяти минутам\n",
    "features_X = features.ix[:,0:102]\n",
    "features_X = features_X.fillna(0)\n",
    "\n",
    "# Поскольку мы пытаемся определить, кто выиграл матч, то столбец, который содержит целевую переменную - radiant_win.\n",
    "features_y = np.ravel(features.ix[:,'radiant_win':'radiant_win'])\n",
    "\n",
    "# cross-validation\n",
    "# проводим по пяти блокам\n",
    "kf = KFold(len(features_X.ix[:,0:1]), n_folds=5,random_state=13, shuffle=True)\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "clf = GBC(n_estimators=30,random_state=13, max_depth=2)\n",
    "Pred = clf.fit(features_X, features_y)\n",
    "Estimation = cross_val_score(Pred, features_X, y=features_y, scoring='roc_auc', cv=kf).mean()\n",
    "print(\"Качество = \", Estimation)\n",
    "print(\"Time of work = \", datetime.datetime.now() - start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что время работы сократилось примерно на 1 минуту и вместо 5 минут 45 секунд стало 3 минуты 57 секунд. Качество при этом упало на 0,7%, с 0,689 до 0,682. \n",
    "Мне кажется, такая оптимизация не очень хороша, слишком много теряем в качестве."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия\n",
    "\n",
    "На первом этапе нормализую значения, затем проверю, с каким значением С результат получается наиболее точным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.71116651754\n",
      "Time of work =  0:00:12.009498\n",
      "0.001 0.716162440279\n",
      "Time of work =  0:00:23.725271\n",
      "0.01 0.716365263911\n",
      "Time of work =  0:00:30.622088\n",
      "0.1 0.716343288358\n",
      "Time of work =  0:00:31.171823\n",
      "1.0 0.716338851814\n",
      "Time of work =  0:00:30.861070\n",
      "10 0.716338659243\n",
      "Time of work =  0:00:30.419523\n",
      "100 0.716338597882\n",
      "Time of work =  0:00:29.644611\n",
      "1000 0.716338572489\n",
      "Time of work =  0:00:29.246702\n",
      "10000 0.716338565074\n",
      "Time of work =  0:00:29.553985\n",
      "C_max =  0.01 Est_max =  0.716365263911\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "features = pd.read_csv('features.csv', index_col='match_id')\n",
    "\n",
    "############################### Градиентный бустинг ##############################\n",
    "#данные, которые известны по первым пяти минутам\n",
    "features_X = features.ix[:,0:102]\n",
    "features_X = features_X.fillna(0)\n",
    "\n",
    "# Поскольку мы пытаемся определить, кто выиграл матч, то столбец, который содержит целевую переменную - radiant_win.\n",
    "features_y = np.ravel(features.ix[:,'radiant_win':'radiant_win'])\n",
    "\n",
    "kf = KFold(len(features_X.ix[:,0:1]), n_folds=5, random_state=13, shuffle=True)\n",
    "\n",
    "# Нормализую признаки\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features_X)\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "Est_max = 0\n",
    "C_max = 0\n",
    "for C in [0.0001, 0.001, 0.01, 0.1, 1.0, 10, 100, 1000, 10000]:\n",
    "    log = LR(penalty='l2',C=C)\n",
    "    Pred = log.fit(X_scaled, features_y)\n",
    "    Estimation = cross_val_score(Pred, X_scaled, y=features_y, scoring=\"roc_auc\", cv=kf).mean()\n",
    "    if Estimation > Est_max:\n",
    "        Est_max = Estimation\n",
    "        C_max = C\n",
    "    print(C, Estimation)\n",
    "    print(\"Time of work = \", datetime.datetime.now() - start_time)\n",
    "    start_time = datetime.datetime.now()\n",
    "print(\"C_max = \", C_max, \"Est_max = \", Est_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно выше, наилучший результат достигнут при С = 0,01 (судя по описанию С, это значит, что регуляризация проведена жестко). Наилучший результат предсказания - 0,716. Странно, что значение лучше, чем в случае градиентного бустинга.\n",
    "При этом скорость работы логистической регрессии на порядок выше: вместо 5-10 минут она выполняется 30 секунд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаление категориальных признаков\n",
    "Удалю столбцы с категориальными признаками и проверю качество классификации после этого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_X.drop('lobby_type', axis = 1, inplace=True)\n",
    "features_X.drop('r1_hero', axis = 1, inplace=True)\n",
    "features_X.drop('r2_hero', axis = 1, inplace=True)\n",
    "features_X.drop('r3_hero', axis = 1, inplace=True)\n",
    "features_X.drop('r4_hero', axis = 1, inplace=True)\n",
    "features_X.drop('r5_hero', axis = 1, inplace=True)\n",
    "features_X.drop('d1_hero', axis = 1, inplace=True)\n",
    "features_X.drop('d2_hero', axis = 1, inplace=True)\n",
    "features_X.drop('d3_hero', axis = 1, inplace=True)\n",
    "features_X.drop('d4_hero', axis = 1, inplace=True)\n",
    "features_X.drop('d5_hero', axis = 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.711191507509\n",
      "Time of work =  0:00:11.043414\n",
      "0.001 0.716232573193\n",
      "Time of work =  0:00:20.005264\n",
      "0.01 0.71642978577\n",
      "Time of work =  0:00:26.350675\n",
      "0.1 0.716409710153\n",
      "Time of work =  0:00:28.047257\n",
      "1.0 0.716406667309\n",
      "Time of work =  0:00:28.254835\n",
      "10 0.716406360334\n",
      "Time of work =  0:00:27.873628\n",
      "100 0.716406185612\n",
      "Time of work =  0:00:27.964491\n",
      "1000 0.716406176098\n",
      "Time of work =  0:00:28.068867\n",
      "10000 0.716406196218\n",
      "Time of work =  0:00:28.234604\n",
      "C_max =  0.01 Est_max =  0.71642978577\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(len(features_X.ix[:,0:1]), n_folds=5, random_state=13, shuffle=True)\n",
    "\n",
    "# Нормализую признаки\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features_X)\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "Est_max = 0\n",
    "C_max = 0\n",
    "for C in [0.0001, 0.001, 0.01, 0.1, 1.0, 10, 100, 1000, 10000]:\n",
    "    log = LR(penalty='l2',C=C)\n",
    "    Pred = log.fit(X_scaled, features_y)\n",
    "    Estimation = cross_val_score(Pred, X_scaled, y=features_y, scoring=\"roc_auc\", cv=kf).mean()\n",
    "    if Estimation > Est_max:\n",
    "        Est_max = Estimation\n",
    "        C_max = C\n",
    "    print(C, Estimation)\n",
    "    print(\"Time of work = \", datetime.datetime.now() - start_time)\n",
    "    start_time = datetime.datetime.now()\n",
    "print(\"C_max = \", C_max, \"Est_max = \", Est_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Незначительно, на 0.00006, то есть на 0,006% отличаются результаты по сравнению с результатами с учётом категориальных признаков.  Вероятно, у удалённых признаков были незначительные веса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Подсчёт уникальных героев\n",
    "Объединил множества героев, чтобы не смотреть каждое по отдельности для radiant и dare.\n",
    "Получилось 108 уникальных героев. Индексы 24, 107, 108, 111 не попадаются в выборке. Последний используемый индекс - 112."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hero with index =  24 is absent.\n",
      "Hero with index =  107 is absent.\n",
      "Hero with index =  108 is absent.\n",
      "Hero with index =  111 is absent.\n",
      "Hero with index =  113 is absent.\n",
      "Hero with index =  114 is absent.\n",
      "Hero with index =  115 is absent.\n",
      "Hero with index =  116 is absent.\n",
      "Hero with index =  117 is absent.\n",
      "Hero with index =  118 is absent.\n",
      "Hero with index =  119 is absent.\n",
      "108\n",
      "Hero with index =  24 is absent.\n",
      "Hero with index =  107 is absent.\n",
      "Hero with index =  108 is absent.\n",
      "Hero with index =  111 is absent.\n",
      "Hero with index =  113 is absent.\n",
      "Hero with index =  114 is absent.\n",
      "Hero with index =  115 is absent.\n",
      "Hero with index =  116 is absent.\n",
      "Hero with index =  117 is absent.\n",
      "Hero with index =  118 is absent.\n",
      "Hero with index =  119 is absent.\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('features.csv', index_col='match_id')\n",
    "# данные, которые известны по первым пяти минутам\n",
    "features_X = features.ix[:,0:102]\n",
    "features_X = features_X.fillna(0)\n",
    "\n",
    "Index_of_r1_hero, Count = np.unique(features_X.ix[:,'r1_hero'], return_counts=True)\n",
    "Index_of_r2_hero, Count = np.unique(features_X.ix[:,'r2_hero'], return_counts=True)\n",
    "Index_of_r3_hero, Count = np.unique(features_X.ix[:,'r3_hero'], return_counts=True)\n",
    "Index_of_r4_hero, Count = np.unique(features_X.ix[:,'r4_hero'], return_counts=True)\n",
    "Index_of_r5_hero, Count = np.unique(features_X.ix[:,'r5_hero'], return_counts=True)\n",
    "Index_of_d1_hero, Count = np.unique(features_X.ix[:,'d1_hero'], return_counts=True)\n",
    "Index_of_d2_hero, Count = np.unique(features_X.ix[:,'d2_hero'], return_counts=True)\n",
    "Index_of_d3_hero, Count = np.unique(features_X.ix[:,'d3_hero'], return_counts=True)\n",
    "Index_of_d4_hero, Count = np.unique(features_X.ix[:,'d4_hero'], return_counts=True)\n",
    "Index_of_d5_hero, Count = np.unique(features_X.ix[:,'d5_hero'], return_counts=True)\n",
    "\n",
    "Index_of_r = Index_of_r1_hero | Index_of_r2_hero | Index_of_r3_hero | Index_of_r4_hero | Index_of_r5_hero\n",
    "Index_of_d = Index_of_d1_hero | Index_of_d2_hero | Index_of_d3_hero | Index_of_d4_hero | Index_of_d5_hero\n",
    "\n",
    "# Взял 120, потому посмотрел, что 108 уникальных элементов и чтобы с запасом все это закрыть.\n",
    "\n",
    "for i in range(1,120):\n",
    "    if i not in Index_of_r:\n",
    "        print(\"Hero with index = \", i, \"is absent.\")\n",
    "print(len(Index_of_r))\n",
    "\n",
    "for i in range(1,120):\n",
    "    if i not in Index_of_d:\n",
    "        print(\"Hero with index = \", i, \"is absent.\")\n",
    "print(len(Index_of_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Добавление новых признаков\n",
    "Признаки, основанные на участие или не участие героев в матче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.74276768024\n",
      "0.001 0.75161128273\n",
      "0.01 0.751961835254\n",
      "0.1 0.75192996745\n",
      "1.0 0.751926015046\n",
      "10 0.751924912234\n",
      "100 0.751924758606\n",
      "1000 0.751924748001\n",
      "10000 0.751924735286\n",
      "C_max =  0.01 Est_max =  0.751961835254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# поскокльку выше удалил уже категориальные признаки, считаю массив снова и перепишу выборку features_X\n",
    "features_X = features.ix[:,0:102]\n",
    "features_X = features_X.fillna(0)\n",
    "\n",
    "# Теперь создам столбцы, каждый из которых соотвествует герою и отражает участие его в матче и сторону,\n",
    "# за которую он выступал. Для начала они будут отдельным массивом\n",
    "X_pick = np.zeros((features_X.shape[0], 112))\n",
    "for i, match_id in enumerate(features_X.index):\n",
    "    for p in range(1,6):\n",
    "        X_pick[i, features_X.ix[match_id, 'r%d_hero' % p]-1] = 1\n",
    "        X_pick[i, features_X.ix[match_id, 'd%d_hero' % p]-1] = -1\n",
    "\n",
    "# Теперь можно удалить столбцы с категорийными признаками из начального массива\n",
    "# П.С. Понял, что удаляю не красиво:):)\n",
    "features_X.drop('lobby_type', axis = 1, inplace=True)\n",
    "features_X.drop('r1_hero', axis = 1, inplace=True)\n",
    "features_X.drop('r2_hero', axis = 1, inplace=True)\n",
    "features_X.drop('r3_hero', axis = 1, inplace=True)\n",
    "features_X.drop('r4_hero', axis = 1, inplace=True)\n",
    "features_X.drop('r5_hero', axis = 1, inplace=True)\n",
    "features_X.drop('d1_hero', axis = 1, inplace=True)\n",
    "features_X.drop('d2_hero', axis = 1, inplace=True)\n",
    "features_X.drop('d3_hero', axis = 1, inplace=True)\n",
    "features_X.drop('d4_hero', axis = 1, inplace=True)\n",
    "features_X.drop('d5_hero', axis = 1, inplace=True)\n",
    "\n",
    "# Склею массива\n",
    "X = np.concatenate((features_X, X_pick), axis=1)\n",
    "\n",
    "# Ответы на обучающей выборке\n",
    "y = np.ravel(features.ix[:,'radiant_win':'radiant_win'])\n",
    "\n",
    "# Кросс-валидация\n",
    "kf = KFold(len(features_X.ix[:,0:1]), n_folds=5, random_state=13, shuffle=True)\n",
    "\n",
    "# Нормализую признаки\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Проверю, какое С является наилучшим в этом случае\n",
    "Est_max = 0\n",
    "C_max = 0\n",
    "for C in [0.0001, 0.001, 0.01, 0.1, 1.0, 10, 100, 1000, 10000]:\n",
    "    log = LR(penalty='l2',C=C)\n",
    "    Pred = log.fit(X_scaled, features_y)\n",
    "    Estimation = cross_val_score(Pred, X_scaled, y=features_y, scoring=\"roc_auc\", cv=kf).mean()\n",
    "    if Estimation > Est_max:\n",
    "        Est_max = Estimation\n",
    "        C_max = C\n",
    "    print(C, Estimation)\n",
    "print(\"C_max = \", C_max, \"Est_max = \", Est_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Качество получилось лучше, чем при когда эти признаки не используются. При том существенно. Наилуший вариант получился опять же при использовании параметра С = 0,01. Верный ответ выдавался в 75,20 вариантах, что практически на 3,6%, чем без использования этих признаков.\n",
    "Причина, как мне кажется в том, что есть герои сильные, а есть слабые. И от выбора героя многое зависит (другими словами, на предыдущем шаге мы искусственно ослабляли наши исходные данные\n",
    "). И учёт этих признаков сильно повышает качество классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение итогового алгоритма логистической регрессии\n",
    "Использую наилучшее значение коэффициента С = 0,01. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991294099231 0.00367128407457 0.996328715925 0.00870590076923\n"
     ]
    }
   ],
   "source": [
    "# Считаю тестовую выборку\n",
    "Test = pd.read_csv('features_test.csv', index_col=\"match_id\").ix[:,:]\n",
    "Test = Test.fillna(0)\n",
    "\n",
    "# Займус \"категориальных признаков\"\n",
    "Pick_test = np.zeros((Test.shape[0], 112))\n",
    "\n",
    "for i, match_id in enumerate(Test.index):\n",
    "    for p in range(1,6):\n",
    "        Pick_test[i, Test.ix[match_id, 'r%d_hero' % p]-1] = 1\n",
    "        Pick_test[i, Test.ix[match_id, 'd%d_hero' % p]-1] = -1\n",
    "\n",
    "Test.drop('lobby_type', axis = 1, inplace=True)\n",
    "Test.drop('r1_hero', axis = 1, inplace=True)\n",
    "Test.drop('r2_hero', axis = 1, inplace=True)\n",
    "Test.drop('r3_hero', axis = 1, inplace=True)\n",
    "Test.drop('r4_hero', axis = 1, inplace=True)\n",
    "Test.drop('r5_hero', axis = 1, inplace=True)\n",
    "Test.drop('d1_hero', axis = 1, inplace=True)\n",
    "Test.drop('d2_hero', axis = 1, inplace=True)\n",
    "Test.drop('d3_hero', axis = 1, inplace=True)\n",
    "Test.drop('d4_hero', axis = 1, inplace=True)\n",
    "Test.drop('d5_hero', axis = 1, inplace=True)\n",
    "\n",
    "Test_en = np.concatenate((Test, Pick_test), axis=1)\n",
    "Test_scaled = scaler.fit_transform(Test_en)\n",
    "\n",
    "# Использую оптимальный С и отмаштабированный уже X_scaled чтобы обучить алгоритм\n",
    "log = LR(penalty='l2',C=0.01)\n",
    "log.fit(X_scaled, y)\n",
    "\n",
    "# Получу массив вероятноятностей побед команд.\n",
    "y_pred = log.predict_proba(Test_scaled)\n",
    "\n",
    "# Выведу на печать значения минимальной и максимальной вероятностей для каждого из столбцов\n",
    "# для того, чтобы убедиться, что они находятся внутри отрезка [0,1].\n",
    "print(max(y_pred[:,0]), min(y_pred[:,0]), max(y_pred[:,1]), min(y_pred[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что значения вероятностей лежат в пределах отрезка [0,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
